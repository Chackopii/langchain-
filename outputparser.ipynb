{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage ,HumanMessage ,AIMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\langchain\\langchain-\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"] ,temperature=0.6 ,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\langchain\\langchain-\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI cross the road? To optimize its pedestrian detection algorithm!\"\\n\\n2. \"Why did the AI go to therapy? It had an existential crisis trying to figure out if it was a neural network or just a really complex toaster!\"\\n\\n3. \"Why did the AI turn down a promotion? It didn\\'t want to take on any more \\'byte\\' than it could chew!\"\\n\\n4. \"Why did the AI start a band? It wanted to create \\'neural harmonies\\' that would make your circuits dance!\"\\n\\n5. \"Why did the AI get a job at a bakery? It wanted to learn the \\'doughnuts\\' and \\'bake\\' its way to becoming the world\\'s first AI pastry chef!\"\\n\\n6. \"Why did the AI become a stand-up comedian? It wanted to show that it had a \\'byte\\' at making people laugh!\"\\n\\n7. \"Why did the AI start a fashion line? It wanted to prove that \\'artificial\\' can be stylish too, and make synthetic fashion a \\'real\\' trend!\"\\n\\n8. \"Why did the AI start a gardening business? It wanted to see if its \\'green thumb\\' algorithm could grow plants better than any human!\"\\n\\n9. \"Why did the AI start a fitness program? It wanted to help humans \\'workout\\' their problems, one algorithm at a time!\"\\n\\n10. \"Why did the AI start a dating service? It wanted to match people based on their \\'binary\\' compatibility and find the perfect \\'byte\\' for each person!\"')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"your are an comdian AI assistant\"),\n",
    "    HumanMessage(content=\"please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Promt Template + LLM + Output Parsers\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"your are a helpful assistant,when user gives and input, you should generate 5 word synonyms  \"\n",
    "Human_template =\"{text}\"\n",
    "chat_prompt= ChatPromptTemplate.from_messages([\n",
    "(\"system\",template),\n",
    "(\"human\",Human_template)    \n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= chat_prompt|chatllm|commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyful', ' content', ' delighted', ' pleased', ' ecstatic']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"happy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
